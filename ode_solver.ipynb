{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from general import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func(t, y):\n",
    "#     dy = -y\n",
    "#     return dy\n",
    "\n",
    "class Func:\n",
    "    def __init__(self, input):\n",
    "        self.cvA = nn.Conv2d(3, 3, 3, padding='same')\n",
    "        self.cvB = nn.Conv2d(3, 3, 3, padding='same')\n",
    "        self.Ib = 0.1\n",
    "        self.input = input\n",
    "    \n",
    "    def __call__(self, t, y):\n",
    "        return self.forward(t, y)\n",
    "\n",
    "    def cnn(self, x):\n",
    "        return 0.5 * (abs(x + 1) - abs(x - 1))\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        dy = -y + self.Ib + self.cvB(self.input) + self.cvA(self.cnn(y))\n",
    "        return dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2057919/3381009038.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "_, (input, label) = next(enumerate(train_loader))    \n",
    "input = torch.tensor(input, dtype=torch.float)\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt:  1.1111111111111112\n",
      "\n",
      "Euler time: 0.3276\n",
      "tensor([-0.5963, -0.7258, -0.7618, -0.7838, -0.7638, -0.7838, -0.7964, -0.7832,\n",
      "        -0.7869, -0.7729], grad_fn=<SliceBackward0>)\n",
      "\n",
      "RK4 time: 0.0072\n",
      "tensor([-0.6081, -0.7313, -0.7534, -0.7719, -0.7760, -0.7850, -0.7867, -0.7882,\n",
      "        -0.7809, -0.7745], grad_fn=<SliceBackward0>)\n",
      "\n",
      "RK4_altstep time: 0.0168\n",
      "tensor([-0.6080, -0.7314, -0.7534, -0.7720, -0.7761, -0.7850, -0.7869, -0.7883,\n",
      "        -0.7810, -0.7745], grad_fn=<SliceBackward0>)\n",
      "\n",
      "torchdiff_ode: 0.0068\n",
      "tensor([-0.6080, -0.7314, -0.7534, -0.7720, -0.7761, -0.7850, -0.7869, -0.7883,\n",
      "        -0.7810, -0.7745], grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2057919/1535411001.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ode_result = odeint(func, y0=torch.tensor(y0), t=torch.tensor(t), method='rk4')\n"
     ]
    }
   ],
   "source": [
    "func = Func(input=input)\n",
    "t = np.linspace(0, 10, 10)\n",
    "print('dt: ', t[1]-t[0])\n",
    "\n",
    "y0 = input\n",
    "start1 = time.time()\n",
    "y = odesolver(y0, t, dt=t[1]-t[0], func=func)\n",
    "end1 = time.time()\n",
    "print(f'\\nEuler time: {(end1-start1):.4f}')\n",
    "print(y[-1][0, 0, 1, :10])\n",
    "\n",
    "start2 = time.time()\n",
    "y = RK4solver(y0, t, dt=t[1]-t[0], func=func)\n",
    "end2 = time.time()\n",
    "print(f'\\nRK4 time: {(end2-start2):.4f}')\n",
    "print(y[-1][0, 0, 1, :10])\n",
    "\n",
    "start3 = time.time()\n",
    "y = RK4_altstep_solver(y0, t, dt=t[1]-t[0], func=func)\n",
    "end3 = time.time()\n",
    "print(f'\\nRK4_altstep time: {(end3-start3):.4f}')\n",
    "print(y[-1][0, 0, 1, :10])\n",
    "\n",
    "start4 = time.time()\n",
    "ode_result = odeint(func, y0=torch.tensor(y0), t=torch.tensor(t), method='rk4')\n",
    "end4 = time.time()\n",
    "print(f'\\ntorchdiff_ode: {(end4-start4):.4f}')\n",
    "print(ode_result[-1][0, 0, 1, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odeint_warpper(t):\n",
    "    return odeint(func, y0=torch.tensor(y0), t=torch.tensor(t, dtype=torch.float), method='rk4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiprocessing():\n",
    "    from multiprocessing import get_context\n",
    "    with get_context(\"spawn\").Pool(2) as pool:\n",
    "        # ode_result = pool.map(odeint_warpper, [t[i*nfine: (i+1)*nfine] for i in range(t_fine_len)])\n",
    "        ode_result = pool.map(odeint_warpper, [t[: 5], t[5: 2*5]])\n",
    "    return ode_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfine: 5\n",
      "len.t:10, len.t_coarse:3, dt: 1, dt_coarse: 5\n",
      "[0 5 9]\n",
      "\n",
      "Euler time (coarse): 0.0024\n",
      "tensor([-0.7118, -0.6931, -0.7951, -0.7403, -0.7537, -0.7395, -0.7448, -0.7996,\n",
      "        -0.7755, -0.7971], grad_fn=<SliceBackward0>)\n",
      "\n",
      "torchdiff_ode time (fine): 0.0213\n",
      "total time: 0.0250\n",
      "tensor([-0.7659,  0.4542,  0.6074,  0.6161,  0.6146,  0.6054,  0.5958,  0.5832,\n",
      "         0.5756,  0.5638], grad_fn=<SliceBackward0>)\n",
      "\n",
      "Euler time: 0.0061\n",
      "tensor([-1.9297, -3.7464, -3.7872, -3.7833, -3.7822, -3.7705, -3.7626, -3.7565,\n",
      "        -3.7776, -3.8094], grad_fn=<SliceBackward0>)\n",
      "\n",
      "torchdiff_ode: 0.0109\n",
      "tensor([-1.9296, -3.7429, -3.7851, -3.7820, -3.7810, -3.7695, -3.7614, -3.7551,\n",
      "        -3.7761, -3.8081], grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3705023/1988813105.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ode_result = odeint(func, y0=torch.tensor(y0), t=torch.tensor(t, dtype=torch.float), method='rk4')\n"
     ]
    }
   ],
   "source": [
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "func = Func(input=input)\n",
    "step_fine = 1\n",
    "step_coarse = 5\n",
    "t = np.arange(0, 10, step_fine)\n",
    "nfine = step_coarse // step_fine\n",
    "print(f'nfine: {nfine}')\n",
    "t_fine_len = t.shape[0] // nfine\n",
    "t_coarse = [t[i*nfine] for i in range(t_fine_len)]\n",
    "t_coarse = t_coarse if t_coarse[-1] == t[-1] else t_coarse + [t[-1]]\n",
    "t_coarse = np.array(t_coarse)\n",
    "\n",
    "# t_coarse = np.array([i for i in np.arange(0, t[-1]+step_coarse-1, step_coarse)])\n",
    "\n",
    "print(f'len.t:{t.shape[0]}, len.t_coarse:{t_coarse.shape[0]}, dt: {t[1]-t[0]}, dt_coarse: {t_coarse[1]-t_coarse[0]}')\n",
    "print(t_coarse)\n",
    "y0 = input\n",
    "\n",
    "start_coarse = time.time()\n",
    "y_coarse = odesolver(y0, t_coarse, dt=t_coarse[1]-t_coarse[0], func=func)\n",
    "end_coarse = time.time()\n",
    "print(f'\\nEuler time (coarse): {(end_coarse-start_coarse):.4f}')\n",
    "print(y[-1][0, 0, 1, :10])\n",
    "\n",
    "\n",
    "start_fine = time.time()\n",
    "# ode_result = run_multiprocessing()\n",
    "with Pool(2) as pool:\n",
    "    # ode_result = pool.map(odeint_warpper, [t[i*nfine: (i+1)*nfine] for i in range(t_fine_len)])\n",
    "    ode_result = pool.map(odeint_warpper, [t[: nfine], t[nfine: 2*nfine]])\n",
    "\n",
    "# for i in range(1):\n",
    "#     ode_result.append(odeint(func, y0=torch.tensor(y0), t=torch.tensor(t[i*nfine: (i+1)*nfine], dtype=torch.float), method='rk4'))\n",
    "\n",
    "end_fine = time.time()\n",
    "print(f'\\ntorchdiff_ode time (fine): {(end_fine-start_fine):.4f}')\n",
    "print(f'total time: {(end_fine-start_coarse):.4f}')\n",
    "print(ode_result[-1][-1][0, 0, 1, :10])\n",
    "\n",
    "start1 = time.time()\n",
    "y = odesolver(y0, t, dt=t[1]-t[0], func=func)\n",
    "end1 = time.time()\n",
    "print(f'\\nEuler time: {(end1-start1):.4f}')\n",
    "print(y[-1][0, 0, 1, :10])\n",
    "\n",
    "start4 = time.time()\n",
    "ode_result = odeint(func, y0=torch.tensor(y0), t=torch.tensor(t, dtype=torch.float), method='rk4')\n",
    "end4 = time.time()\n",
    "print(f'\\ntorchdiff_ode: {(end4-start4):.4f}')\n",
    "print(ode_result[-1][0, 0, 1, :10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
